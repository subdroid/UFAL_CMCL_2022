Job resources: hard resource_list:         gpu=4,gpu_ram=2G
Assigned GPUs:  0 1 2 3
LRC:ubuntu 18.04: SGE 8.1.9 configured...
INFO:training log:Initiating data copy
INFO:numexpr.utils:Note: NumExpr detected 31 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 8.
INFO:numexpr.utils:NumExpr defaulting to 8 threads.
INFO:training log:Category: TRTAvg
INFO:training log:Loading BERT tokenizer and model
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): huggingface.co:443
DEBUG:urllib3.connectionpool:https://huggingface.co:443 "HEAD /xlm-roberta-base/resolve/main/tokenizer_config.json HTTP/1.1" 404 0
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): huggingface.co:443
DEBUG:urllib3.connectionpool:https://huggingface.co:443 "HEAD /xlm-roberta-base/resolve/main/config.json HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): huggingface.co:443
DEBUG:urllib3.connectionpool:https://huggingface.co:443 "GET /api/models/xlm-roberta-base HTTP/1.1" 200 784
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): huggingface.co:443
DEBUG:urllib3.connectionpool:https://huggingface.co:443 "HEAD /xlm-roberta-base/resolve/main/sentencepiece.bpe.model HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): huggingface.co:443
DEBUG:urllib3.connectionpool:https://huggingface.co:443 "HEAD /xlm-roberta-base/resolve/main/tokenizer.json HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): huggingface.co:443
DEBUG:urllib3.connectionpool:https://huggingface.co:443 "HEAD /xlm-roberta-base/resolve/main/added_tokens.json HTTP/1.1" 404 0
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): huggingface.co:443
DEBUG:urllib3.connectionpool:https://huggingface.co:443 "HEAD /xlm-roberta-base/resolve/main/special_tokens_map.json HTTP/1.1" 404 0
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): huggingface.co:443
DEBUG:urllib3.connectionpool:https://huggingface.co:443 "HEAD /xlm-roberta-base/resolve/main/tokenizer_config.json HTTP/1.1" 404 0
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): huggingface.co:443
DEBUG:urllib3.connectionpool:https://huggingface.co:443 "HEAD /xlm-roberta-base/resolve/main/config.json HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): huggingface.co:443
DEBUG:urllib3.connectionpool:https://huggingface.co:443 "HEAD /xlm-roberta-base/resolve/main/config.json HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): huggingface.co:443
DEBUG:urllib3.connectionpool:https://huggingface.co:443 "HEAD /xlm-roberta-base/resolve/main/pytorch_model.bin HTTP/1.1" 302 0
Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.bias']
- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
INFO:training log:Selecting device
INFO:training log:Initiate tokenization
INFO:training log:epoch 1 of 100
INFO:training log:Average training loss: 110.653493
INFO:training log:Training epoch duration: 0:19:17
INFO:training log:Validation phase
INFO:training log:  Validation loss: 110.857610
INFO:training log:  Validation duration: 0:00:14
INFO:training log:  Validation accuracy: 7.1677289033673475
INFO:training log:epoch 2 of 100
INFO:training log:Average training loss: 90.795481
INFO:training log:Training epoch duration: 0:19:16
INFO:training log:Validation phase
INFO:training log:  Validation loss: 119.839686
INFO:training log:  Validation duration: 0:00:14
INFO:training log:  Validation accuracy: 8.113324377954621
INFO:training log:epoch 3 of 100
INFO:training log:Average training loss: 86.224398
INFO:training log:Training epoch duration: 0:19:15
INFO:training log:Validation phase
INFO:training log:  Validation loss: 89.775012
INFO:training log:  Validation duration: 0:00:14
INFO:training log:  Validation accuracy: 6.541306655431531
INFO:training log:epoch 4 of 100
INFO:training log:Average training loss: 79.017324
INFO:training log:Training epoch duration: 0:19:15
INFO:training log:Validation phase
INFO:training log:  Validation loss: 88.859703
INFO:training log:  Validation duration: 0:00:14
INFO:training log:  Validation accuracy: 6.505251706260996
INFO:training log:epoch 5 of 100
INFO:training log:Average training loss: 76.529212
INFO:training log:Training epoch duration: 0:19:15
INFO:training log:Validation phase
INFO:training log:  Validation loss: 107.692643
INFO:training log:  Validation duration: 0:00:14
INFO:training log:  Validation accuracy: 7.008275738081982
INFO:training log:epoch 6 of 100
INFO:training log:Average training loss: 72.599505
INFO:training log:Training epoch duration: 0:19:15
INFO:training log:Validation phase
INFO:training log:  Validation loss: 83.500926
INFO:training log:  Validation duration: 0:00:14
INFO:training log:  Validation accuracy: 6.5131281718765335
INFO:training log:epoch 7 of 100
INFO:training log:Average training loss: 67.609189
INFO:training log:Training epoch duration: 0:19:15
INFO:training log:Validation phase
INFO:training log:  Validation loss: 88.809235
INFO:training log:  Validation duration: 0:00:14
INFO:training log:  Validation accuracy: 6.411360705636211
INFO:training log:epoch 8 of 100
INFO:training log:Average training loss: 65.510159
INFO:training log:Training epoch duration: 0:19:15
INFO:training log:Validation phase
INFO:training log:  Validation loss: 87.762230
INFO:training log:  Validation duration: 0:00:14
INFO:training log:  Validation accuracy: 6.393879838825501
INFO:training log:epoch 9 of 100
INFO:training log:Average training loss: 60.953492
INFO:training log:Training epoch duration: 0:19:15
INFO:training log:Validation phase
INFO:training log:  Validation loss: 93.817684
INFO:training log:  Validation duration: 0:00:14
INFO:training log:  Validation accuracy: 6.4942322391824625
INFO:training log:epoch 10 of 100
INFO:training log:Average training loss: 58.009525
INFO:training log:Training epoch duration: 0:19:15
INFO:training log:Validation phase
INFO:training log:  Validation loss: 89.791412
INFO:training log:  Validation duration: 0:00:14
INFO:training log:  Validation accuracy: 6.447314234124017
INFO:training log:epoch 11 of 100
INFO:training log:Average training loss: 57.246499
INFO:training log:Training epoch duration: 0:19:15
INFO:training log:Validation phase
INFO:training log:  Validation loss: 85.424091
INFO:training log:  Validation duration: 0:00:14
INFO:training log:  Validation accuracy: 6.428539718549276
INFO:training log:epoch 12 of 100
INFO:training log:Average training loss: 54.233173
INFO:training log:Training epoch duration: 0:19:15
INFO:training log:Validation phase
INFO:training log:  Validation loss: 93.689370
INFO:training log:  Validation duration: 0:00:14
INFO:training log:  Validation accuracy: 6.50889038486579
INFO:training log:epoch 13 of 100
INFO:training log:Average training loss: 51.603867
INFO:training log:Training epoch duration: 0:19:15
INFO:training log:Validation phase
INFO:training log:  Validation loss: 87.579270
INFO:training log:  Validation duration: 0:00:14
INFO:training log:  Validation accuracy: 6.437800138881526
INFO:training log:epoch 14 of 100
INFO:training log:Average training loss: 49.637089
INFO:training log:Training epoch duration: 0:19:15
INFO:training log:Validation phase
INFO:training log:  Validation loss: 85.945202
INFO:training log:  Validation duration: 0:00:14
INFO:training log:  Validation accuracy: 6.416061474490411
INFO:training log:epoch 15 of 100
======= EPILOG: Wed Jan 5 12:19:51 CET 2022
== Limits:   gpu=4,gpu_ram=2G
== Usage:    cpu=04:38:27, mem=55632.99289 GB s, io=23.22370 GB, vmem=3.246G, maxvmem=5.395G
== Duration: 04:39:05 (16745 s)
== Server name: tdll5
